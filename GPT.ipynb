{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shiveshrane/Research_paper_implementations/blob/main/GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I3YcMrZ060G"
      },
      "source": [
        "# Decoder-only transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ACtSRT3IepQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6-RrdbeIfDJ",
        "outputId": "0a232870-badf-4a2b-9c91-534518cee99a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-23 13:42:53--  https://raw.githubusercontent.com/karpathy/ng-video-lecture/refs/heads/master/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-01-23 13:42:53 (26.6 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/ng-video-lecture/refs/heads/master/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyF_RGPzIiH2"
      },
      "outputs": [],
      "source": [
        "with open('input.txt', 'r') as f:\n",
        "  text=f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcaSdn8hIlZV",
        "outputId": "da6138c1-4fdf-42d0-e318-3692e987e6ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        }
      ],
      "source": [
        "print(len(text)) ## Length of text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spJLYCAEInJj",
        "outputId": "7b869b6c-c802-4b8c-8166-5c66a4bf83fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ],
      "source": [
        "chars=sorted(list(set(text)))\n",
        "vocab_size=len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzpwsNVpIpAb",
        "outputId": "75f89bf6-d614-4f26-c8cb-8916bf91f5ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ],
      "source": [
        "stoi={ch:i for i,ch in enumerate(chars)}\n",
        "itos={i:ch for i,ch in enumerate(chars)}\n",
        "encode=lambda s:[stoi[c] for c in s]\n",
        "decode=lambda l:''.join([itos[i] for i in l])\n",
        "\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tddGJl2kIqfk",
        "outputId": "dad3c2b0-eeba-43f5-e831-1e476a5a4bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1115394,) <dtype: 'int64'>\n",
            "tf.Tensor(\n",
            "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
            "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
            " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
            "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
            "  0 37 53 59  1 39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39\n",
            " 58 46 43 56  1 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47\n",
            " 57 46 12  0  0 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53\n",
            " 50 60 43 42  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47\n",
            " 56 57 58  6  1 63 53 59  1 49 52 53 61  1 15 39 47 59 57  1 25 39 56 41\n",
            " 47 59 57  1 47 57  1 41 46 47 43 44  1 43 52 43 51 63  1 58 53  1 58 46\n",
            " 43  1 54 43 53 54 50 43  8  0  0 13 50 50 10  0 35 43  1 49 52 53 61  5\n",
            " 58  6  1 61 43  1 49 52 53 61  5 58  8  0  0 18 47 56 57 58  1 15 47 58\n",
            " 47 64 43 52 10  0 24 43 58  1 59 57  1 49 47 50 50  1 46 47 51  6  1 39\n",
            " 52 42  1 61 43  5 50 50  1 46 39 60 43  1 41 53 56 52  1 39 58  1 53 59\n",
            " 56  1 53 61 52  1 54 56 47 41 43  8  0 21 57  5 58  1 39  1 60 43 56 42\n",
            " 47 41 58 12  0  0 13 50 50 10  0 26 53  1 51 53 56 43  1 58 39 50 49 47\n",
            " 52 45  1 53 52  5 58 11  1 50 43 58  1 47 58  1 40 43  1 42 53 52 43 10\n",
            "  1 39 61 39 63  6  1 39 61 39 63  2  0  0 31 43 41 53 52 42  1 15 47 58\n",
            " 47 64 43 52 10  0 27 52 43  1 61 53 56 42  6  1 45 53 53 42  1 41 47 58\n",
            " 47 64 43 52 57  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 35\n",
            " 43  1 39 56 43  1 39 41 41 53 59 52 58 43 42  1 54 53 53 56  1 41 47 58\n",
            " 47 64 43 52 57  6  1 58 46 43  1 54 39 58 56 47 41 47 39 52 57  1 45 53\n",
            " 53 42  8  0 35 46 39 58  1 39 59 58 46 53 56 47 58 63  1 57 59 56 44 43\n",
            " 47 58 57  1 53 52  1 61 53 59 50 42  1 56 43 50 47 43 60 43  1 59 57 10\n",
            "  1 47 44  1 58 46 43 63  0 61 53 59 50 42  1 63 47 43 50 42  1 59 57  1\n",
            " 40 59 58  1 58 46 43  1 57 59 54 43 56 44 50 59 47 58 63  6  1 61 46 47\n",
            " 50 43  1 47 58  1 61 43 56 43  0 61 46 53 50 43 57 53 51 43  6  1 61 43\n",
            "  1 51 47 45 46 58  1 45 59 43 57 57  1 58 46 43 63  1 56 43 50 47 43 60\n",
            " 43 42  1 59 57  1 46 59 51 39 52 43 50 63 11  0 40 59 58  1 58 46 43 63\n",
            "  1 58 46 47 52 49  1 61 43  1 39 56 43  1 58 53 53  1 42 43 39 56 10  1\n",
            " 58 46 43  1 50 43 39 52 52 43 57 57  1 58 46 39 58  0 39 44 44 50 47 41\n",
            " 58 57  1 59 57  6  1 58 46 43  1 53 40 48 43 41 58  1 53 44  1 53 59 56\n",
            "  1 51 47 57 43 56 63  6  1 47 57  1 39 57  1 39 52  0 47 52 60 43 52 58\n",
            " 53 56 63  1 58 53  1 54 39 56 58 47 41 59 50 39 56 47 57 43  1 58 46 43\n",
            " 47 56  1 39 40 59 52 42 39 52 41 43 11  1 53 59 56  0 57 59 44 44 43 56\n",
            " 39 52 41 43  1 47 57  1 39  1 45 39 47 52  1 58 53  1 58 46 43 51  1 24\n",
            " 43 58  1 59 57  1 56 43 60 43 52 45 43  1 58 46 47 57  1 61 47 58 46  0\n",
            " 53 59 56  1 54 47 49 43 57  6  1 43 56 43  1 61 43  1 40 43 41 53 51 43\n",
            "  1 56 39 49 43 57 10  1 44 53 56  1 58 46 43  1 45 53 42 57  1 49 52 53\n",
            " 61  1 21  0 57 54 43 39 49  1 58 46 47 57  1 47 52  1 46 59 52 45 43 56\n",
            "  1 44 53 56  1 40 56 43 39 42  6  1 52 53 58  1 47 52  1 58 46 47 56 57\n",
            " 58  1 44 53 56  1 56 43 60 43 52 45 43  8  0  0], shape=(1000,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "## Convert entire data into a tensor\n",
        "data=tf.convert_to_tensor(encode(text), dtype=tf.int64)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjHmRkMcIxuk",
        "outputId": "187edc67-3305-4b37-cf04-318246526746"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([18, 47, 56, 57, 58,  1, 15, 47, 58])>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_len=int(0.9*len(data))\n",
        "train_data=data[:train_len]\n",
        "val_data=data[train_len:]\n",
        "block_size=8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFKpl1vSI2ZA",
        "outputId": "07c60a9d-6d5a-44d5-80bb-ef4b7c97cc7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is [18] the target: 18\n",
            "when input is [18 47] the target: 47\n",
            "when input is [18 47 56] the target: 56\n",
            "when input is [18 47 56 57] the target: 57\n",
            "when input is [18 47 56 57 58] the target: 58\n",
            "when input is [18 47 56 57 58  1] the target: 1\n",
            "when input is [18 47 56 57 58  1 15] the target: 15\n",
            "when input is [18 47 56 57 58  1 15 47] the target: 47\n"
          ]
        }
      ],
      "source": [
        "## Creating X and Y\n",
        "X=train_data[:block_size]\n",
        "Y=train_data[:block_size+1]\n",
        "for t in range (block_size):\n",
        "  context=X[:t+1]\n",
        "  target=Y[t]\n",
        "  print(f\"when input is {context} the target: {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag4zNEo-I7SX",
        "outputId": "3e44a629-5a18-403d-fa18-62e6d3f10884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "(4, 8)\n",
            "[[ 1 51 63  1 41 53 39 58]\n",
            " [39 42  0 20 47 57  1 52]\n",
            " [32 53  1 56 43 60 43 50]\n",
            " [54 39 52 63  1 54 47 43]]\n",
            "targets:\n",
            "(4, 8)\n",
            "[[51 63  1 41 53 39 58  6]\n",
            " [42  0 20 47 57  1 52 39]\n",
            " [53  1 56 43 60 43 50  1]\n",
            " [39 52 63  1 54 47 43 41]]\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(1337)\n",
        "batch_size=4\n",
        "block_size=8\n",
        "\n",
        "def get_batch(split):\n",
        "  data=train_data if split=='train' else val_data\n",
        "  ix=tf.random.uniform((batch_size,), minval=0, maxval=len(data)-block_size, dtype=tf.int32)\n",
        "  x=tf.stack([data[i:i+block_size] for i in ix])\n",
        "  y=tf.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x,y\n",
        "\n",
        "xb,yb=get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb.numpy())\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb.numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqDA63irIZRS"
      },
      "outputs": [],
      "source": [
        "class AttentionHeadDecoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, head_size):\n",
        "    super(AttentionHeadDecoder, self).__init__()\n",
        "    self.key=tf.keras.layers.Dense(head_size, use_bias=False)\n",
        "    self.query=tf.keras.layers.Dense(head_size, use_bias=False)\n",
        "    self.value=tf.keras.layers.Dense(head_size, use_bias=False)\n",
        "    self.tril=tf.constant(tf.linalg.band_part(tf.ones(shape=(block_size,block_size)),-1, 0))\n",
        "    self.dropout=tf.keras.layers.Dropout(dropout)\n",
        "    self.head_size=head_size\n",
        "\n",
        "  def call(self, x):\n",
        "    B,T,C=x.shape\n",
        "    k=self.key(x)\n",
        "    q=self.query(x)\n",
        "\n",
        "    weights=tf.matmul(q, tf.transpose(k, perm=[0, 2, 1])) * tf.math.rsqrt(tf.cast(k.shape[-1], tf.float32))\n",
        "    weights=tf.where(self.tril[:T, :T]==0,-np.inf, weights) ## This makes it decoder block, since we arent getting the language model.\n",
        "    weights=tf.nn.softmax(weights, axis=-1)\n",
        "    weights=self.dropout(weights)\n",
        "    v=self.value(x)\n",
        "    output=tf.matmul(weights, v)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r89A1tvBIQUm"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionDecoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_heads, head_size):\n",
        "    super(MultiHeadAttentionDecoder, self).__init__()\n",
        "    self.heads=[AttentionHeadDecoder(head_size) for _ in range(num_heads)]\n",
        "    self.projection=tf.keras.layers.Dense(n_embd)\n",
        "    self.dropout=tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "  def call(self, x):\n",
        "    output=tf.concat([h(x) for h in self.heads], axis=-1)\n",
        "    output=self.projection(output)\n",
        "    output=self.dropout(output)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igfYnQ5qIUC8"
      },
      "outputs": [],
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, n_embd):\n",
        "    super(FeedForward, self).__init__()\n",
        "    self.ffnet=tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(4*n_embd),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        tf.keras.layers.Dense(n_embd),\n",
        "        tf.keras.layers.Dropout(dropout)\n",
        "    ])\n",
        "  def call(self, x):\n",
        "    return self.ffnet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJIGALFUI-Vw"
      },
      "outputs": [],
      "source": [
        "class Block(tf.keras.layers.Layer):\n",
        "  def __init__(self, n_embd, n_head):\n",
        "    super(Block, self).__init__()\n",
        "    head_size=n_embd//n_head\n",
        "    self.sa=MultiHeadAttentionDecoder(n_head, head_size)\n",
        "    self.ff=FeedForward(n_embd)\n",
        "    self.ln1=tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.ln2=tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "  def call(self, x):\n",
        "    x=x+self.sa(self.ln1(x))\n",
        "    x=x+self.ff(self.ln2(x))\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDsT51NiJCii"
      },
      "outputs": [],
      "source": [
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CtFQfEkJEsm"
      },
      "outputs": [],
      "source": [
        "class GptModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size):\n",
        "    super(GptModel, self).__init__()\n",
        "    self.token_embedding_table=tf.keras.layers.Embedding(vocab_size, n_embd)\n",
        "    self.position_embedding_table=tf.keras.layers.Embedding(block_size, n_embd)\n",
        "    self.blocks=tf.keras.Sequential([Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "    self.layerNorm=tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.lm_head=tf.keras.layers.Dense(vocab_size, kernel_initializer='normal')\n",
        "\n",
        "  def call(self, idx, targets=None):\n",
        "    B,T=idx.shape\n",
        "    tok_embd=self.token_embedding_table(idx) # (Batch, time, channel) size\n",
        "    pos_embd=self.position_embedding_table(tf.range(T, dtype=tf.float32)) # (time, channel)\n",
        "    x=tok_embd+pos_embd #(B,T,C)\n",
        "    x=self.blocks(x)\n",
        "    x=self.layerNorm(x)\n",
        "    logits=self.lm_head(x) #(B,T,vocab_size)\n",
        "\n",
        "    if targets is None:\n",
        "      losses2=None\n",
        "    else:\n",
        "      B, T,C=logits.shape\n",
        "      logits=tf.reshape(logits,shape=(B*T,C) )\n",
        "      targets=tf.reshape(targets, shape=(B*T,))\n",
        "      losses2=tf.keras.losses.sparse_categorical_crossentropy(targets, logits, from_logits=True)\n",
        "      #losses2=tf.reduce_mean(losses2)\n",
        "    return logits, losses2\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      idx_conditionals=idx[:, -block_size:]\n",
        "      logits, loss=self(idx_conditionals)\n",
        "      logits=logits[:, -1, :] #becomes( B, C)\n",
        "      probs=tf.nn.softmax(logits, axis=-1)\n",
        "      idx_next=tf.random.categorical(tf.math.log(probs), num_samples=1, dtype=tf.int64) #(B,1)\n",
        "      idx=tf.concat([idx, idx_next],axis=1) # (B, T+1)\n",
        "    return idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKQq1wecJMEt",
        "outputId": "9922ecca-77a8-4ddc-9dee-4f98b87f7c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.209729 M parameters\n"
          ]
        }
      ],
      "source": [
        "gpt_model=GptModel(vocab_size)\n",
        "# Create a dummy input\n",
        "dummy_input = tf.zeros((1, block_size), dtype=tf.int32)\n",
        "# Call the model with the dummy input to build it\n",
        "_ ,_= gpt_model(dummy_input)\n",
        "# Now you can access the trainable variables\n",
        "print(sum(tf.size(v).numpy() for v in gpt_model.trainable_variables)/1e6, 'M parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXOk4KnZaRo8"
      },
      "outputs": [],
      "source": [
        "def test_model(model):\n",
        "  decoder_input = tf.random.uniform(\n",
        "        (batch_size, block_size),\n",
        "        minval=0,\n",
        "        maxval=vocab_size,\n",
        "        dtype=tf.int32\n",
        "    )\n",
        "  decoder_output, loss=model(decoder_input)\n",
        "  print(f\"decoder input-->{decoder_input}, decoder output-->{decoder_output}\")\n",
        "  print(decoder_input.shape,decoder_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb8bIoiEalhI",
        "outputId": "3cdfd841-7d2a-4952-dd88-1d0669c8bc7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decoder input-->[[ 1  8  4 60 24 19  5 10 54 29 40 47 15  6 37  6 43 56  1 48 55  1  5 22\n",
            "  45 31 58 40 18 45 47 57]\n",
            " [50  3 22 32 20 36 35 24  7 26  2 39 48 33 20 64 27 52 44 26 54 51 30 32\n",
            "  28 44 40 23 60 41 26 30]\n",
            " [44 52 38  2 19  7  3 47 20 57 54 44 64 21 47 22 19 22  3 28 13 24 31 35\n",
            "  24 32 11 52 60 40  1 55]\n",
            " [13 40 30 50 18 27 26 61 42  2 21 38 64 51 14 50 63 52 62 22 17 63  4 10\n",
            "  47 33 33 23 48 60 51 21]\n",
            " [16 18  5  0 33 62 11  2 40 48 56 57 63 50 27 14 59  3 45 61 19  4  6 25\n",
            "  64  8 61 35  1 62 64 45]\n",
            " [19 10 13 27 59 13 16 20  9  5 61 40  3  8 29 27 45 63 45 23 42 33 52 15\n",
            "  27 51 23 57 41 45  9 18]\n",
            " [40 11 42 57 47 39 30 34 18 32  7 46 36  6 11  2 36 18 13 18 16 46 31 33\n",
            "  54  1 11 30 18 46 19 27]\n",
            " [39 41 13 19 62  5  4 14 12 10 13 39 34 24  1 17  2 43 52 39 15 45 48 16\n",
            "  37 62 33 24 37 60 31 53]\n",
            " [27 30 24  1 33  1 11 51 24 35 16 37 60 20  9 50 21  5 60 18 19 42 38 11\n",
            "  46  7 35 38 49 36  7 56]\n",
            " [39 47 57 20 62 37 53 33 58 34 35 19  3 33  5 19 15  5 62 20 59 39 61 61\n",
            "  53  3 20 32  0 57 56 42]\n",
            " [40  7 45 16 62 10 16 64 10 38 48 24 39 45 37  5 41  7 32 63 18 22  5 62\n",
            "   0 54 50  8 63 23 48 12]\n",
            " [21 13 24 15 14 22 15 18  2 64 53 48 62  7 23  7 36 28 13 37 25 34 11 19\n",
            "   1 56 14 20 44 34 25 32]\n",
            " [ 1 63 55 37 45 56 21 55 40 63 17 34 34 17 32 35 14 26 50 21  5 64 48 41\n",
            "  46  6 43  8 39 35 36  8]\n",
            " [28 53 40 62 64 64 50 44 48 19 16 10 10 34 21 31 23 64 59 45 49 12 20 48\n",
            "  64  5 44 58 52 46 35 46]\n",
            " [47 26 41 58 28 63 49 31 46 56 23 31 48 48 39 37 28  3 63 39 26 63 18 10\n",
            "  52  7 45 23  4 58  2 24]\n",
            " [21 10 45 28  8 41  9 59 32 34 43 48  2  6 42 64 45 62  2 32  3 30 54  3\n",
            "  10 54 20 37 42 31 46 16]], decoder output-->[[[-1.40879333e-01  3.55071843e-01 -2.35044360e-01 ... -6.94305971e-02\n",
            "    2.18114868e-01 -1.17298877e+00]\n",
            "  [ 7.81642273e-03  3.27922821e-01 -2.05452278e-01 ... -1.54205665e-01\n",
            "    2.60668695e-01 -1.34831381e+00]\n",
            "  [ 4.77645010e-01  9.12623584e-01 -4.44520086e-01 ... -4.32878524e-01\n",
            "    4.97029573e-02 -1.28304422e+00]\n",
            "  ...\n",
            "  [ 5.00924528e-01  7.82666802e-01 -1.50424421e-01 ...  2.28436247e-01\n",
            "    1.47870770e-02 -4.75531071e-01]\n",
            "  [ 2.88689733e-01  8.96052420e-01 -3.34207356e-01 ... -1.34338796e-01\n",
            "    1.86701313e-01 -4.08604413e-01]\n",
            "  [ 3.22739422e-01  9.15697038e-01 -3.86543483e-01 ...  1.29622146e-01\n",
            "    2.72212505e-01 -4.24705595e-01]]\n",
            "\n",
            " [[ 2.70116687e-01  3.03098500e-01 -8.94087330e-02 ... -3.62073421e-01\n",
            "   -2.14376196e-01 -9.47126508e-01]\n",
            "  [ 6.90969467e-01  6.32385910e-01 -2.17289478e-01 ... -1.62682101e-01\n",
            "   -3.77166897e-01 -7.66433358e-01]\n",
            "  [ 6.70304835e-01  8.54102790e-01 -1.72758088e-01 ... -1.00595988e-01\n",
            "   -3.52280796e-01 -8.89242828e-01]\n",
            "  ...\n",
            "  [ 6.95342302e-01  8.97592425e-01  1.82896343e-04 ...  3.18026751e-01\n",
            "   -1.60221636e-01 -3.41884613e-01]\n",
            "  [ 4.69051301e-01  9.64032710e-01 -7.36267865e-02 ...  4.21912849e-01\n",
            "   -1.21020146e-01 -1.95960142e-02]\n",
            "  [ 5.67732334e-01  1.05042303e+00  1.71670243e-01 ...  3.42563570e-01\n",
            "   -2.68040806e-01 -6.71021789e-02]]\n",
            "\n",
            " [[ 3.76727790e-01  5.79765558e-01 -1.37440383e-01 ...  3.45928162e-01\n",
            "    3.87517691e-01 -3.11255753e-01]\n",
            "  [ 4.28977787e-01  4.11632329e-01 -2.64454097e-01 ...  8.55975151e-01\n",
            "    4.28840257e-02 -1.55074388e-01]\n",
            "  [ 5.21394789e-01  5.86384535e-01 -4.63275015e-01 ...  6.16171837e-01\n",
            "   -1.24224380e-01 -4.43861157e-01]\n",
            "  ...\n",
            "  [ 3.94700050e-01  3.41339976e-01 -1.30028650e-01 ...  8.65076959e-01\n",
            "    1.31077701e-02  3.27605963e-01]\n",
            "  [ 4.50638920e-01  6.59995258e-01 -2.03299254e-01 ...  3.65386844e-01\n",
            "    6.34450093e-02  3.77587557e-01]\n",
            "  [ 3.85633171e-01  6.48769557e-01 -5.20887598e-03 ...  5.76951861e-01\n",
            "    6.83436245e-02  2.42507920e-01]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 7.68385753e-02 -1.58886656e-01 -7.91473165e-02 ... -1.76411688e-01\n",
            "   -4.65590544e-02 -6.16631508e-01]\n",
            "  [ 2.65765816e-01  2.65584767e-01 -2.93059111e-01 ... -1.94170758e-01\n",
            "   -3.67171824e-01 -6.25898242e-01]\n",
            "  [ 2.46108443e-01  5.58546424e-01 -3.44096214e-01 ... -3.17190558e-01\n",
            "   -7.71447942e-02 -2.57595271e-01]\n",
            "  ...\n",
            "  [ 6.34211302e-01  4.44012374e-01 -4.25634176e-01 ...  3.44056427e-01\n",
            "   -2.72581130e-01  7.19416559e-01]\n",
            "  [ 5.69020629e-01  3.70380938e-01 -3.12006682e-01 ...  3.31594944e-01\n",
            "   -2.27993920e-01  5.53058863e-01]\n",
            "  [ 4.13584858e-01  4.32798922e-01 -5.40058017e-01 ...  2.87728965e-01\n",
            "   -1.02190815e-01  6.90729380e-01]]\n",
            "\n",
            " [[ 6.10943660e-02  2.81889498e-01  8.06669295e-02 ... -7.17250258e-02\n",
            "   -9.47364941e-02 -1.00539839e+00]\n",
            "  [ 3.42650682e-01  3.58190328e-01 -1.67815387e-01 ...  9.93653908e-02\n",
            "   -3.18801910e-01 -9.02503550e-01]\n",
            "  [ 2.81523764e-01  6.12219930e-01 -4.54239547e-01 ...  4.70551811e-02\n",
            "   -1.51579067e-01 -9.89532888e-01]\n",
            "  ...\n",
            "  [ 3.66672099e-01  5.35481095e-01 -3.52995366e-01 ...  2.22407039e-02\n",
            "   -4.88804996e-01  1.80112690e-01]\n",
            "  [ 2.25541443e-01  6.14183366e-01 -4.97192085e-01 ... -2.35994071e-01\n",
            "   -1.76348463e-01 -7.68428519e-02]\n",
            "  [ 7.05413073e-02  2.81814039e-01 -4.20873523e-01 ... -1.72514364e-01\n",
            "   -1.78437442e-01  7.09374547e-02]]\n",
            "\n",
            " [[ 3.32275122e-01 -6.63989708e-02 -6.17260188e-02 ...  1.54731989e-01\n",
            "   -1.43575892e-01 -2.76083469e-01]\n",
            "  [ 5.60132980e-01  6.29157713e-03  9.55728162e-03 ...  6.17367089e-01\n",
            "   -2.20359638e-01 -2.40595654e-01]\n",
            "  [ 3.39116544e-01  9.15232077e-02 -3.19079071e-01 ...  1.89466745e-01\n",
            "   -3.81068081e-01 -4.50889736e-01]\n",
            "  ...\n",
            "  [ 4.41286713e-01  8.14966977e-01 -5.78114092e-01 ...  1.84612170e-01\n",
            "    7.29961842e-02 -2.16562767e-03]\n",
            "  [ 2.62170970e-01  7.97578216e-01 -2.98417538e-01 ...  1.50306940e-01\n",
            "    1.63049489e-01  2.56622136e-01]\n",
            "  [ 6.20899081e-01  4.90428090e-01 -1.83158964e-01 ...  4.22847092e-01\n",
            "   -1.71968222e-01 -2.66664866e-02]]]\n",
            "(16, 32) (16, 32, 65)\n"
          ]
        }
      ],
      "source": [
        "test_model(gpt_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLQOJDz8JOKJ"
      },
      "outputs": [],
      "source": [
        "#@tf.function\n",
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    model.trainable=False\n",
        "    for split in ['train', 'val']:\n",
        "        losses=tf.TensorArray(tf.float32, size=eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = gpt_model(X, Y)\n",
        "            losses=losses.write(k, loss)\n",
        "        out[split] = losses.stack().numpy().mean()\n",
        "    model.trainable=True\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVOWdLYIJO8C"
      },
      "outputs": [],
      "source": [
        "optimizer_gpt=tf.keras.optimizers.AdamW(learning_rate=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_ghHIiMJRUW",
        "outputId": "e03cb4b5-8429-440a-ce3e-ae00493088c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step: 0, train loss: 4.307332515716553, val loss: 4.3081955909729\n",
            "step: 500, train loss: 2.2909929752349854, val loss: 2.297534465789795\n",
            "step: 1000, train loss: 2.071084976196289, val loss: 2.1373119354248047\n",
            "step: 1500, train loss: 1.9506285190582275, val loss: 2.0400304794311523\n",
            "step: 2000, train loss: 1.8504546880722046, val loss: 1.9740591049194336\n",
            "step: 2500, train loss: 1.7997691631317139, val loss: 1.9491997957229614\n",
            "step: 3000, train loss: 1.7531301975250244, val loss: 1.9270868301391602\n",
            "step: 3500, train loss: 1.728566288948059, val loss: 1.8933018445968628\n",
            "step: 4000, train loss: 1.705342411994934, val loss: 1.8675044775009155\n",
            "step: 4500, train loss: 1.6775745153427124, val loss: 1.8529760837554932\n"
          ]
        }
      ],
      "source": [
        "#batch_size=32\n",
        "for steps in range(max_iters):\n",
        "  if steps%eval_interval==0:\n",
        "    losses=estimate_loss(gpt_model)\n",
        "    print(f\"step: {steps}, train loss: {losses['train']}, val loss: {losses['val']}\")\n",
        "  xb, yb=get_batch('train')\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits2, loss2=gpt_model(xb, yb)\n",
        "    gradients=tape.gradient(loss2, gpt_model.trainable_variables)\n",
        "    optimizer_gpt.apply_gradients(zip(gradients, gpt_model.trainable_variables))\n",
        "#print(loss2.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhUdck52JU3U",
        "outputId": "13afe074-ddb6-40f1-b70d-96cf44e9bf02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Edwere while follow, 'erm he what you be hast.\n",
            "\n",
            "DEMINket doss I meak but neadied to fait.\n",
            "\n",
            "JULIET:\n",
            "The the spuch: my as their didishing.\n",
            "\n",
            "Muslove's fatter thus, any my if\n",
            "Meandun. Boble let move on sad, dest at here yours, come lave by fallow;\n",
            "Whem look I her speeak agen my doss: spirs,\n",
            "Misfeel homes what he consweed no pasold as I know gill the regive your will'd you badd handugo now\n",
            "wo prober ower good I have have as he would peop your honour\n",
            "And to be the's true in combe the paow an that: and shall you; you grundy!\n",
            "To for Romemercy tell I low in proisider these will a stave agains!\n",
            "\n",
            "ESCALUS:\n",
            "Bair you havy the sayem your rinces,\n",
            "Is plearelings the effied no pavy me, to lamberacame\n",
            "Pard he fast: say, chall meang you,\n",
            "Let leaves it that I kere's spear,\n",
            "Which is fail enry heaving your clour,\n",
            "Shot doot, but a why bear'd has giery sand that pospled a the painter of 'best take be' pright daught,\n",
            "Be a\n",
            "the excuse his belandsom, he do commpose yore bohander this be twemand's see I me\n",
            "Let now tull be in thy blood, he moaider buit east,\n",
            "Ere bemis, sarwy some oather wier your tomem of Bedge fortune, I'll hy his swears of no dear shome a spacter\n",
            "Tefore, a gimpoy o' Racecy?\n",
            "\n",
            "Havose sevendly else mitsen,\n",
            "What no gross you, where those chup and him\n",
            "And Angerlows an much then whichinks our ham, the grot if you, no, no shame that as you? obem I many thee queen,\n",
            "I have shopens, you, and upon house\n",
            "Shall him thee fatter is cown you, my thou bes of he she!\n",
            "A whose shall cray it: an Sbut to his true,\n",
            "My plose to the mother I am words his.\n",
            "\n",
            "Fir Venry Come Duke those to at as come?\n",
            "\n",
            "LARWICHI't, to, his yet and me leove there's was thou remsed,\n",
            "Her he how stups, steting Stooman, it thou have many leve\n",
            "Concason, With an phe, till o' on a That power\n",
            "Your mine very what well you neest gest did not it:\n",
            "I unbleartle treah, lyoN thone\n",
            "O's sent to them up Hape\n",
            "Cainst my deared! Come me you awer! I my,\n",
            "Lord Hereford citif the lese sedildeging. Some, Ovoice I wit me?\n",
            "Hame's smy at that this fors y\n"
          ]
        }
      ],
      "source": [
        "context=tf.zeros(shape=(1,1), dtype=tf.int64)\n",
        "print(decode(gpt_model.generate(context, max_new_tokens=2000)[0].numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyM_YgHsJVgI"
      },
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0URJKOHJXpH"
      },
      "outputs": [],
      "source": [
        "## Saving the model weights\n",
        "gpt_model.save_weights('gpt_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXj4vV-LilFs"
      },
      "source": [
        "# Transformer using tensorflow-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3fmhhNcB2Bi"
      },
      "source": [
        "#### Positonal encoding in pytorch see it to fix your encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj4Po-CSWVoq"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, max_len=5000):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.max_len = max_len\n",
        "    pe=tf.zeros(shape=(max_len, d_model))\n",
        "    positions=tf.expand_dims(tf.range(0, max_len, dtype=tf.float32), axis=1)\n",
        "    div_term=tf.exp(tf.range(0, d_model, 2, dtype=tf.float32) * -(math.log(10000.0) / d_model))\n",
        "    i_vals=tf.cast(tf.range(d_model), dtype=tf.float32)\n",
        "    pe=tf.concat([\n",
        "        [tf.sin(pos/(10000**(2*i/d_model))) if i%2==0 else\n",
        "        tf.cos(pos/(10000**(2*i/d_model)))\n",
        "        for i in i_vals]\n",
        "        for pos in positions\n",
        "    ], axis=0)\n",
        "    pe=pe[tf.newaxis, :, :] ### check\n",
        "    self.pe=tf.Variable(pe, trainable=False)\n",
        "    self.dropout=tf.keras.layers.Dropout(0.1)\n",
        "\n",
        "  def call(self, x):\n",
        "    #op= x+tf.transpose(self.pe[:tf.shape(x)[1], :])\n",
        "    print(f\"shape is-->{ x.shape}, pe shape-> {self.pe[:tf.shape(x)[1], :].shape}\")\n",
        "    op=x+self.pe[tf.newaxis, :tf.shape(x)[1], :]\n",
        "    return self.dropout(op)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN4Dl0kUGm0C"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, max_len=5000):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.max_len = max_len\n",
        "    pe=np.zeros(shape=(max_len, d_model), dtype=np.float32)\n",
        "    positions=tf.expand_dims(tf.range(0, max_len, dtype=tf.float32), axis=1)\n",
        "    div_term=tf.exp(tf.range(0, d_model, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / d_model))\n",
        "    i_vals=tf.cast(tf.range(d_model), dtype=tf.float32)\n",
        "    pe[:, 0::2] = tf.sin(positions * div_term)\n",
        "    pe[:, 1::2] = tf.cos(positions * div_term)\n",
        "    self.pe=tf.Variable(pe, trainable=False)\n",
        "    self.dropout=tf.keras.layers.Dropout(0.1)\n",
        "\n",
        "  def call(self, x):\n",
        "    #op= x+tf.transpose(self.pe[:tf.shape(x)[1], :])\n",
        "    #print(f\"shape is-->{ x.shape}, pe shape-> {self.pe[:tf.shape(x)[1], :].shape}\")\n",
        "    #op=x+self.pe[:tf.shape(x)[1], :]\n",
        "    op=x+tf.expand_dims(self.pe[:tf.shape(x)[1], :], axis=0)\n",
        "    return self.dropout(op)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkKThn2Rwlhl"
      },
      "outputs": [],
      "source": [
        "def test_positonal_encoding():\n",
        "  d_model=64\n",
        "  max_len=32\n",
        "  x=tf.random.uniform(shape=(1, max_len), maxval=vocab_size,dtype=tf.int32)\n",
        "  embed=Embedding(vocab_size, d_model)\n",
        "  pe=PositionalEncoding(d_model, max_len)\n",
        "  print(x.shape)\n",
        "  x=embed(x)\n",
        "  print(x.shape)\n",
        "  op=pe(x)\n",
        "  print(op.shape)\n",
        "  print(op)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auNfTFVEV9wd"
      },
      "outputs": [],
      "source": [
        "class Embedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super(Embedding, self).__init__()\n",
        "    self.embedding=tf.keras.layers.Embedding(vocab_size, d_model)\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.embedding(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwSivYwWxh33",
        "outputId": "7825017d-ef24-4760-84d8-4d35afeb42a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 32)\n",
            "(1, 32, 64)\n",
            "(1, 32, 64)\n",
            "tf.Tensor(\n",
            "[[[ 2.9965367e-02  9.7622323e-01 -6.2834099e-04 ...  9.5219421e-01\n",
            "    1.1789013e-02  1.0149907e+00]\n",
            "  [ 8.5415262e-01  5.3590965e-01  7.2832125e-01 ...  1.0037460e+00\n",
            "   -1.4083704e-03  9.6254164e-01]\n",
            "  [ 9.1822082e-01 -4.2171818e-01  1.0372987e+00 ...  9.9012125e-01\n",
            "   -3.3736184e-02  1.0192972e+00]\n",
            "  ...\n",
            "  [-6.3590962e-01 -7.5702393e-01  2.1274668e-01 ...  1.0133574e+00\n",
            "   -1.1203975e-02  9.8147833e-01]\n",
            "  [-9.7006452e-01  1.7915165e-01 -4.9107462e-01 ...  1.0339257e+00\n",
            "   -4.0074687e-02  9.7387457e-01]\n",
            "  [-3.8931236e-01  9.1204524e-01 -9.5500493e-01 ...  1.0410236e+00\n",
            "   -9.0732351e-03  1.0373031e+00]]], shape=(1, 32, 64), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "test_positonal_encoding()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peNUMHjYUc4k"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(length, depth):\n",
        "    # Use TensorFlow operations instead of NumPy\n",
        "    depth = depth // 2\n",
        "    positions = tf.range(length)[:, tf.newaxis]\n",
        "    depths = tf.range(depth)[tf.newaxis, :] / depth\n",
        "    angle_rates = 1 / (10000 ** tf.cast(depths, tf.float32))\n",
        "    angle_rads = tf.cast(positions, tf.float32) * angle_rates\n",
        "    pos_encoding = tf.concat([tf.sin(angle_rads), tf.cos(angle_rads)], axis=-1)\n",
        "    return pos_encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WswnSqyfUOU6"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model, length=5000):\n",
        "    super(PositionalEmbedding, self).__init__()\n",
        "    self.d_model=d_model\n",
        "    self.embedding=tf.keras.layers.Embedding(vocab_size, d_model)\n",
        "    self.pos_encoding=positional_encoding(length=length, depth=d_model)\n",
        "\n",
        "  def call(self, x):\n",
        "    length=tf.shape(x)[-1]\n",
        "    x=self.embedding(x)\n",
        "    x*=tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x=x+self.pos_encoding[tf.newaxis,\n",
        "                          :length, :]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD3n1GeJVpcI"
      },
      "outputs": [],
      "source": [
        "def test_positional_embedding():\n",
        "  d_model=64\n",
        "  max_len=32\n",
        "  x=tf.random.uniform(shape=(1, max_len), maxval=vocab_size,dtype=tf.int32)\n",
        " # embed=Embedding(vocab_size, d_model)\n",
        "  pe=PositionalEmbedding(vocab_size, d_model, max_len)\n",
        "  print(x.shape)\n",
        "  op=pe(x)\n",
        "  print(op.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj2IxSNIVu1u",
        "outputId": "d5097bc9-5c35-4b71-b4d3-6652e8251dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 32)\n",
            "(1, 32, 64)\n"
          ]
        }
      ],
      "source": [
        "test_positional_embedding()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTMK07NEXyjF"
      },
      "outputs": [],
      "source": [
        "class BaseAttentionLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha=tf.keras.layers.MultiHeadAttention(**kwargs, use_bias=False)\n",
        "    self.layernorm=tf.keras.layers.LayerNormalization()\n",
        "    self.add=tf.keras.layers.Add()\n",
        "    self.dropout=tf.keras.layers.Dropout(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNMBieLhYJTV"
      },
      "outputs": [],
      "source": [
        "class CausalSelfAttention(BaseAttentionLayer):\n",
        "  def call(self, x):\n",
        "    attn_output=self.mha(query=x, value=x, key=x, use_causal_mask=True)\n",
        "    x=self.add([x, attn_output])\n",
        "    x=self.layernorm(x)\n",
        "    x=self.dropout(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMWXISmeYVg3"
      },
      "outputs": [],
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff):\n",
        "    super(FeedForward, self).__init__()\n",
        "    self.ffnet=tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model),\n",
        "        tf.keras.layers.Dropout(0.1)\n",
        "    ])\n",
        "    self.layernorm=tf.keras.layers.LayerNormalization()\n",
        "    self.add=tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x):\n",
        "    ff_output=self.ffnet(x)\n",
        "    x=self.add([x, ff_output])\n",
        "    x=self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKWb_FocYapb"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, dropout=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "    self.causal_attention=CausalSelfAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout)\n",
        "    self.feed_forward=FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x=self.causal_attention(x)\n",
        "    x=self.feed_forward(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ3qN9_QY0ZD"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, dropout=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.d_model=d_model\n",
        "    self.num_layers=num_layers\n",
        "\n",
        "    #self.embedding=Embedding(vocab_size, d_model)\n",
        "    #self.positional_encoding=tf.keras.layers.Embedding(block_size, d_model) # this is just for checking\n",
        "    #self.pos_encoding=PositionalEncoding(d_model)\n",
        "    self.positional_embedding=PositionalEmbedding(vocab_size, d_model)\n",
        "    self.dec_layers=[DecoderLayer(d_model, num_heads, dff, dropout) for _ in range(num_layers)]\n",
        "    self.final_layer=tf.keras.layers.Dense(vocab_size, kernel_initializer='normal')\n",
        "\n",
        "  def call(self,x ):\n",
        "    #x=self.embedding(x)\n",
        "    #x=x+self.positional_encoding(x)\n",
        "    x=self.positional_embedding(x)\n",
        "    for i in range(self.num_layers):\n",
        "      x=self.dec_layers[i](x)\n",
        "    output=self.final_layer(x)\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD8kXSjhaSpk"
      },
      "outputs": [],
      "source": [
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "eval_iters = 500\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxjHZ5abizAS"
      },
      "source": [
        "### Dummy AI based debugging model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbYb2H-rhwL_",
        "outputId": "b6815aa2-d679-4dbb-867c-f9a333c03a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 32)\n",
            "(1, 32, 64)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def positional_encoding(length, depth):\n",
        "    # Use TensorFlow operations instead of NumPy\n",
        "    depth = depth // 2\n",
        "    positions = tf.range(length)[:, tf.newaxis]\n",
        "    depths = tf.range(depth)[tf.newaxis, :] / depth\n",
        "    angle_rates = 1 / (10000 ** tf.cast(depths, tf.float32))\n",
        "    angle_rads = tf.cast(positions, tf.float32) * angle_rates\n",
        "    pos_encoding = tf.concat([tf.sin(angle_rads), tf.cos(angle_rads)], axis=-1)\n",
        "    return pos_encoding\n",
        "\n",
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, d_model, length=5000):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(length=length, depth=d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[-1]\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = x + self.pos_encoding[:length, :]\n",
        "        return x\n",
        "\n",
        "class BaseAttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs, use_bias=False)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.dropout = tf.keras.layers.Dropout(0.1)\n",
        "\n",
        "class CausalSelfAttention(BaseAttentionLayer):\n",
        "    def call(self, x):\n",
        "        attn_output = self.mha(query=x, value=x, key=x, use_causal_mask=True)\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class FeedForward(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, dff):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.ffnet = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model),\n",
        "            tf.keras.layers.Dropout(0.1)\n",
        "        ])\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, x):\n",
        "        ff_output = self.ffnet(x)\n",
        "        x = self.add([x, ff_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.causal_attention = CausalSelfAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout)\n",
        "        self.feed_forward = FeedForward(d_model, dff)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.causal_attention(x)\n",
        "        x = self.feed_forward(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.positional_embedding = PositionalEmbedding(vocab_size, d_model)\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, dropout) for _ in range(num_layers)]\n",
        "        self.final_layer = tf.keras.layers.Dense(vocab_size, kernel_initializer='normal')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.positional_embedding(x)\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.dec_layers[i](x)\n",
        "        output = self.final_layer(x)\n",
        "        return output\n",
        "\n",
        "def test_positional_embedding():\n",
        "    d_model = 64\n",
        "    max_len = 32\n",
        "    vocab_size = 10000  # Define vocab_size\n",
        "    x = tf.random.uniform(shape=(1, max_len), maxval=vocab_size, dtype=tf.int32)\n",
        "    pe = PositionalEmbedding(vocab_size, d_model, max_len)\n",
        "    print(x.shape)\n",
        "    op = pe(x)\n",
        "    print(op.shape)\n",
        "\n",
        "# Run the test\n",
        "test_positional_embedding()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZOC3OrSbn6E"
      },
      "outputs": [],
      "source": [
        "decoder_model=Decoder(num_layers=n_layer, d_model=n_embd, num_heads=n_head, dff=4*n_embd, vocab_size=vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwaKiY4m8X30"
      },
      "source": [
        "#### Loss function for production_decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYwYncKYcFWI"
      },
      "outputs": [],
      "source": [
        "def loss_function(labels, logits):\n",
        "  return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHoQtnrd7xG7"
      },
      "outputs": [],
      "source": [
        "#@tf.function\n",
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    model.trainable=False\n",
        "    for split in ['train', 'val']:\n",
        "        losses=tf.TensorArray(tf.float32, size=eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits=model(X)\n",
        "            loss2=loss_function(Y, logits)\n",
        "            losses=losses.write(k, loss2)\n",
        "        out[split] = losses.stack().numpy().mean()\n",
        "    model.trainable=True\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "vssx-DmT8sDZ",
        "outputId": "3595c4b7-d196-473c-a61f-917c01c0d67d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a90d1329cd48>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-b6d0757c28bf>\u001b[0m in \u001b[0;36mestimate_loss\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mloss2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-d10dbf9b7e2b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-d10dbf9b7e2b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcausal_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-d10dbf9b7e2b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCausalSelfAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseAttentionLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_causal_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/attention/multi_head_attention.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, value, key, query_mask, value_mask, key_mask, attention_mask, return_attention_scores, training, use_causal_mask)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;31m#   H = `size_per_head`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;31m# `query` = [B, T, N ,H]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;31m# `key` = [B, S, N, H]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/einsum_dense.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/numpy.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(subscripts, *operands)\u001b[0m\n\u001b[1;32m   2303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mEinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubscripts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2305\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubscripts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/numpy.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(subscripts, *operands, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         )\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_custom_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubscripts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# TODO: tf.einsum doesn't support integer dtype with gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/numpy.py\u001b[0m in \u001b[0;36muse_custom_ops\u001b[0;34m(subscripts, output_type, *operands)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msubscripts\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"abc,dc->abd\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, grad_a, grad_b, name)\u001b[0m\n\u001b[1;32m   3593\u001b[0m         )\n\u001b[1;32m   3594\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3595\u001b[0;31m         return gen_math_ops.batch_mat_mul_v2(\n\u001b[0m\u001b[1;32m   3596\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3597\u001b[0m             \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, grad_x, grad_y, name)\u001b[0m\n\u001b[1;32m   1637\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1640\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BatchMatMulV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adj_x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adj_y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \"grad_x\", grad_x, \"grad_y\", grad_y)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "out=estimate_loss(decoder_model)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmwfTDrO8ceh"
      },
      "source": [
        "#### Training loop for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "collapsed": true,
        "id": "sMshaDfOc0J6",
        "outputId": "d308f4d3-27db-4d87-aa25-30b326ec11b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss->4.326534271240234, count-->0\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-11595e0ab064>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loss->{ loss}, count-->{steps}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mgradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
          ]
        }
      ],
      "source": [
        "## Training loop\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "for steps in range(max_iters):\n",
        "  xb, yb=get_batch('train')\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits=decoder_model(xb)\n",
        "    loss=loss_function(yb, logits)\n",
        "    print(f\"loss->{ loss}, count-->{steps}\")\n",
        "    gradients=tape.gradient(loss, decoder_model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, decoder_model.trainable_variables))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDdBQI8Wi4qf"
      },
      "source": [
        "## Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6IN_18UgS3b",
        "outputId": "6da0d24c-c059-457b-f350-926af6305c66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:==================================\n",
            "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
            "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7eb5fa294dd0>\n",
            "If you want to mark it as used call its \"mark_used()\" method.\n",
            "It was originally created here:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3578, in run_code\n",
            "    return outflag  File \"<ipython-input-89-f3f86f71cc0c>\", line 6, in <cell line: 0>\n",
            "    losses=estimate_loss(decoder_model)  File \"<ipython-input-82-b6d0757c28bf>\", line 8, in estimate_loss\n",
            "    X, Y = get_batch(split)  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
            "    return _add_should_use_warning(fn(*args, **kwargs),\n",
            "==================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before Gradient Calculation:\n",
            "(16, 32) (16, 32)\n",
            "After Gradient Calculation:\n"
          ]
        }
      ],
      "source": [
        "# Before computing gradients\n",
        "print(\"Before Gradient Calculation:\")\n",
        "for var in decoder_model.trainable_variables:\n",
        "    print(var.name)\n",
        "xb, yb=get_batch('train')\n",
        "print(xb.shape, yb.shape)\n",
        "with tf.GradientTape() as tape:\n",
        "    logits = decoder_model(xb)\n",
        "    loss = loss_function(yb, logits)\n",
        "\n",
        "# After computing gradients\n",
        "print(\"After Gradient Calculation:\")\n",
        "for var in decoder_model.trainable_variables:\n",
        "    print(var.name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFf3NnkUaWKX"
      },
      "outputs": [],
      "source": [
        "decoder_model.compile(optimizer='adamw', loss='sparse_categorical_crossentropy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzddWcX2d1sG",
        "outputId": "c202c0c9-930b-4227-b218-f9fb75c28978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positional_embedding_7: trainable=True\n",
            "decoder_layer_12: trainable=True\n",
            "decoder_layer_13: trainable=True\n",
            "decoder_layer_14: trainable=True\n",
            "decoder_layer_15: trainable=True\n",
            "dense_35: trainable=True\n"
          ]
        }
      ],
      "source": [
        "for layer in decoder_model.layers:\n",
        "    print(f\"{layer.name}: trainable={layer.trainable}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGiyjZnOb_7l"
      },
      "outputs": [],
      "source": [
        "for layer in decoder_model.layers:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNyzJRdBcN1Y",
        "outputId": "0cf0467b-a591-4c62-be76-ed50b9c7bbce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding_8: trainable=True\n",
            "positional_embedding_5: trainable=True\n",
            "decoder_layer_8: trainable=True\n",
            "decoder_layer_9: trainable=True\n",
            "decoder_layer_10: trainable=True\n",
            "decoder_layer_11: trainable=True\n",
            "dense_26: trainable=True\n"
          ]
        }
      ],
      "source": [
        "for layer in decoder_model.layers:\n",
        "    print(f\"{layer.name}: trainable={layer.trainable}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmT6wvsrbMYd",
        "outputId": "359275b9-685a-44a7-b616-153f79f7a630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings\n",
            "kernel\n",
            "kernel\n",
            "kernel\n",
            "kernel\n",
            "gamma\n",
            "beta\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "kernel\n",
            "kernel\n",
            "kernel\n",
            "kernel\n",
            "gamma\n",
            "beta\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "kernel\n",
            "kernel\n",
            "kernel\n",
            "kernel\n",
            "gamma\n",
            "beta\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "kernel\n",
            "kernel\n",
            "kernel\n",
            "kernel\n",
            "gamma\n",
            "beta\n",
            "kernel\n",
            "bias\n",
            "kernel\n",
            "bias\n",
            "gamma\n",
            "beta\n",
            "kernel\n",
            "bias\n"
          ]
        }
      ],
      "source": [
        "for var in decoder_model.trainable_variables:\n",
        "    print(var.name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW1SHmcMfRGv",
        "outputId": "60403796-ee30-4cff-dbbb-dff7f69f010b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 65), dtype=float32, numpy=\n",
              "array([[[ 0.20314631,  0.08497136, -0.8745965 ,  0.11160021,\n",
              "         -0.1377081 , -0.24788046,  0.21647897,  0.5213624 ,\n",
              "          0.29480776, -0.64917105,  0.18583238, -0.37512958,\n",
              "         -0.0262249 ,  0.01239629,  0.93078107, -0.58524305,\n",
              "          0.09809493, -0.47205967, -0.18520868,  0.09592154,\n",
              "         -0.49041814, -0.21090993, -0.16654561,  0.3900448 ,\n",
              "         -0.2523714 ,  0.28446776,  0.37590474,  0.29830053,\n",
              "          0.04083604, -0.23921514,  0.47719157, -0.16996107,\n",
              "          0.07034269,  0.02197703,  0.12283357,  0.11808436,\n",
              "          0.20611233,  0.17101255, -0.13200939, -0.13331053,\n",
              "          0.13868141, -0.19393566, -0.9601563 ,  0.49952084,\n",
              "         -0.02267453,  0.08059627,  0.56349736, -0.24792361,\n",
              "         -0.4541805 , -0.18882255, -0.67917126, -0.0900622 ,\n",
              "         -0.04652077,  0.17453033,  0.4004238 ,  0.8158908 ,\n",
              "         -0.00450779, -0.34449935,  0.38634402, -0.40474808,\n",
              "          0.15729235,  0.33964124, -0.0973185 ,  0.9021934 ,\n",
              "         -0.11295494],\n",
              "        [ 0.07881958,  0.17855406, -0.95059067, -0.18513596,\n",
              "         -0.44956428, -0.5522088 ,  0.18448289,  0.32591176,\n",
              "          0.25615278, -0.6748676 , -0.01201771, -0.6316138 ,\n",
              "         -0.36890396, -0.3484962 ,  0.89063996, -0.2509792 ,\n",
              "         -0.05796209, -0.8757836 ,  0.01380134, -0.11380696,\n",
              "         -0.07912214, -0.20590624, -0.20328689,  0.21427625,\n",
              "         -0.60972327,  0.59353626,  0.5050221 ,  0.13740654,\n",
              "          0.1422293 ,  0.02776064,  0.67788863, -0.49045718,\n",
              "         -0.17585945, -0.45988187,  0.01565493, -0.31164014,\n",
              "         -0.05297273,  0.07327816,  0.04054326, -0.13247313,\n",
              "          0.26494586, -0.25240326, -1.2118734 ,  0.48534173,\n",
              "          0.06124839,  0.0939934 ,  0.73981583, -0.47466865,\n",
              "         -0.27977312, -0.11035547, -0.7202879 , -0.17079866,\n",
              "         -0.03434516,  0.1240463 ,  0.6582527 ,  0.49358094,\n",
              "         -0.45133066, -0.9451736 ,  0.3851995 ,  0.02278191,\n",
              "          0.23023114,  0.44341186,  0.15718596,  0.8215201 ,\n",
              "         -0.06553333]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dummy_input = tf.constant([[1, 32]])  # Replace with appropriate input shape\n",
        "decoder_model(dummy_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaTioJPWi734"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XzcBg5k08Uue",
        "outputId": "6b49d9a4-de0f-4e71-fbc4-4009b7b09e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, train loss: 4.250707149505615, val loss: 4.2519211769104\n",
            "step: 500, train loss: 2.3494510650634766, val loss: 2.358513116836548\n",
            "step: 1000, train loss: 2.1575987339019775, val loss: 2.180633783340454\n",
            "step: 1500, train loss: 2.0135529041290283, val loss: 2.0672426223754883\n",
            "step: 2000, train loss: 1.9311662912368774, val loss: 2.0035011768341064\n",
            "step: 2500, train loss: 1.8728077411651611, val loss: 1.9795480966567993\n",
            "step: 3000, train loss: 1.8267226219177246, val loss: 1.9378784894943237\n",
            "step: 3500, train loss: 1.7934709787368774, val loss: 1.9148969650268555\n",
            "step: 4000, train loss: 1.7521355152130127, val loss: 1.9034076929092407\n",
            "step: 4500, train loss: 1.7239738702774048, val loss: 1.870065450668335\n"
          ]
        }
      ],
      "source": [
        "## Training loop with loss estimate\n",
        "optimizer=tf.keras.optimizers.AdamW(learning_rate=learning_rate)\n",
        "for steps in range(max_iters):\n",
        "  xb, yb=get_batch('train')\n",
        "  if steps%eval_interval==0:\n",
        "    losses=estimate_loss(decoder_model)\n",
        "    print(f\"step: {steps}, train loss: {losses['train']}, val loss: {losses['val']}\")\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits=decoder_model(xb)\n",
        "    #print(xb.shape, yb.shape, logits.shape)\n",
        "    loss=loss_function(yb, logits)\n",
        "    gradients=tape.gradient(loss, decoder_model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, decoder_model.trainable_variables))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXPCalfpeDOn"
      },
      "outputs": [],
      "source": [
        "def generator(decoder_model, idx, max_new_tokens):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_conditionals=idx[:, -block_size:]\n",
        "    logits=decoder_model(idx_conditionals)\n",
        "    logits=logits[:, -1, :]\n",
        "    probs=tf.nn.softmax(logits, axis=-1)\n",
        "    idx_next=tf.random.categorical(tf.math.log(probs), num_samples=1, dtype=tf.int64)\n",
        "    idx=tf.concat([idx, idx_next],axis=1)\n",
        "  return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUu3vhNreRAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9919e624-06ef-4528-fbda-e023ed6578f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "And bainsts.\n",
            "\n",
            "RABELAM:\n",
            "Praliese more gobus grow of his good geent,\n",
            "In my bruch heer chear track his feid combervoak!\n",
            "\n",
            "MENENIUS:\n",
            "This dispose!\n",
            "\n",
            "EdEtward I my save was, with one,\n",
            "welce, you are contry 'to nie; eneese weret worthy roth withom,\n",
            "I som thanstrious men which as weed,\n",
            "I was good see die; and to dey\n",
            "I done us some that would, and hope shaln tear's her's 'four of\n",
            "meved the shorey, fierss her, dispalty,\n",
            "It for for comblen you, and b sod.\n",
            "To daid you see; or there's greal ain was byseet sweet,\n",
            "I poy patcitione revish-your a greemiter.\n",
            "\n",
            "WERWAW:\n",
            "Have so, sir, mones his one for olling you,\n",
            "but yough hath onor tain?\n",
            "\n",
            "MENENIUS:\n",
            "I gray her not one as,\n",
            "comper wortwoms eyencesssiffor so!\n",
            "And fear geneat of jest, feat:\n",
            "To you weseel.\n",
            "\n",
            "LADY NENV:\n",
            "Have no\n",
            "O't:\n",
            "Yesee, sur, Is ame to your you word:\n",
            "Consephind to marre so with once complo\n",
            "orbanis worctcown soack her cound\n",
            "To may fair onote: were unknow's not of\n",
            "Where, no dears; we my shall, shet pirise give as owdering that full'd time\n",
            "Hath speak his stay dasst.\n",
            "\n",
            "AUCH:\n",
            "Yetrances:\n",
            "I put is veoped it!\n",
            "\n",
            "AUFIUS:\n",
            "I nather! Go not in Servil very:; were indeed ye\n",
            "are, good not her times of sea, sherw sord,\n",
            "You seceance, ain to ladven out for lie,\n",
            "I would to kind of Comel-assule: Kife must\n",
            "I'll ake life dies chord.\n",
            "\n",
            "DUDY:\n",
            "To I see his wercouse ow doth\n",
            "is wase to saves, so, thy plows beild.\n",
            "\n",
            "RINV:\n",
            "A you are seem-seor him muse:\n",
            "Good take her no! yief to poison that\n",
            "more of the munders parrose, sain aith?\n",
            "O; we hell's of my ledfid is on well'd us\n",
            "Be you, I'll swide, my make:\n",
            "Tis I dienced Lazed; wont.\n",
            "\n",
            "DUSESTOSTHA?\n",
            "That fatt, now, not say meel.\n",
            "\n",
            "AUMIO:\n",
            "Where art, you proneince carrance him;\n",
            "Which dearing swee:, if will and hopse yeld.\n",
            "This webrous with sweet for gay!\n",
            "Be, all'd thou lace.h Net welcome;\n",
            "Bosome, berop soin, left to my hath,\n",
            "And swors.\n",
            "\n",
            "KIN$s:T I to that love! my have put head the wond challd.\n",
            "\n",
            "AUCEMALTIXETngles new:\n",
            "And swear, theince asp'd the countire:\n",
            "I seat me death, who faremMis deator\n",
            "Is sflewlemed your fear thy bro\n"
          ]
        }
      ],
      "source": [
        "print(decode(generator(decoder_model, tf.zeros(shape=(1,1), dtype=tf.int64), max_new_tokens=2000)[0].numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Save decoder_model\n",
        "decoder_model.save('decoder_model.keras')\n"
      ],
      "metadata": {
        "id": "Ob4-0rlll0qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeQZxz_euGvu"
      },
      "outputs": [],
      "source": [
        "def test_decoder_model(decoder_model):\n",
        "  decoder_input = tf.random.uniform(\n",
        "        (batch_size, block_size),\n",
        "        minval=0,\n",
        "        maxval=vocab_size,\n",
        "        dtype=tf.int32\n",
        "    )\n",
        "  decoder_output=decoder_model(decoder_input)\n",
        "  print(f\"decoder input-->{decoder_input}, decoder output-->{decoder_output}\")\n",
        "  print(decoder_input.shape,decoder_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o2l39koxu3WQ",
        "outputId": "5a9cb7fb-e552-4d97-ea9d-b3c928e47d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decoder input-->[[18 61 22 10 39 45 40 29 53 61  2 34  3 37  2 30 58  5 39 56 59 30 16 32\n",
            "  48 54  7 33 54 18 57 29]\n",
            " [62 26 47 30 38 21 12  8 27 50 14 53 42 59 40 49 14 60 31 58 58 30  0 52\n",
            "  16 22 43 28 28 49 21 60]\n",
            " [14 16 33 26 59 18 54 27 53  4 16 44 45  7 30  0 31 60 15 48 20 34  6 27\n",
            "  28 44 23 23 29 11 45 34]\n",
            " [59 16 11  2  4 58 15 19  4 60 64 33 13 10 52 30 60 43  2 48 31 58 59 27\n",
            "   5 60 32 64 55 20 28 29]\n",
            " [13 64 10 12 11 51 56 60 52 48  6 25 47 26 23 10 63 27  7 62 53 46 10 15\n",
            "  24 31 38 52 27 50 23 43]\n",
            " [ 7 29 12 60 33 61 45 40 34  8 25 19 14 29 64 14 31 35 61 11 46 13 26 34\n",
            "  44 47 25 17 27 15 36 17]\n",
            " [34 46 61 42 54 37 49 60 52 28 26  4 25 18 30 23 20 33  6 57 37 59 24 23\n",
            "  57  8 10  3 54 62  5 19]\n",
            " [37 55 41 45 62 20 34 42 18 39 59 32 32 10 25 62  7 11 61 59  2 45 23 48\n",
            "  13 41  8  4  9 33 24 46]\n",
            " [17 59  7 40 23 50 23 36 19 17 47 64  8 20 11 55 54 12 61 21 34 16 29 60\n",
            "  15 60 53  5 56 53 22 40]\n",
            " [35 17 38 57 40 40 35 53  1 49 38 55 59 56 62  4 24 26 62 49 60 51 44 25\n",
            "  45 10 43 37 20 44 36 59]\n",
            " [44  2 43 46 60 48 34 61  2 39 17 11 30 45 32 28  6 16 58 51 11 44 56  2\n",
            "  43 46 54  7 20 25 16  2]\n",
            " [40  0 23 30 36 26 40 29 44  5 63 18 27 55 50 60 58 46 19 31 28 50 33  9\n",
            "  17 24 16 13  4 35 24 55]\n",
            " [27  7  7 29 14 46 15 40 15 26 23 14 16 35 25 30 28  4 12 47 57  4  5 29\n",
            "  49 29 41 22 54 21 25  8]\n",
            " [58 44 63  5  7 51  1 29 17 36 41  0  5 16  7 21 20 60 35 43 28 28  4 26\n",
            "  36 37 58 29 34 24 12 42]\n",
            " [48 53 64 45 37 34 56 57  3 43 16 29 60 47 30 14 46 11 14  3 35 55 12 49\n",
            "   7 47 22  2 62 26 11 22]\n",
            " [52 14 41 63  9  9 52 17 27 49 58 52  5 13 17 31 10 38 56  3  7  3 55 38\n",
            "  15 47  1 38 61  5 40 35]], decoder output-->[[[ 6.12911843e-02  1.51288331e-01 -3.50470304e-01 ...  1.44792438e-01\n",
            "   -3.90155971e-01 -1.50462836e-01]\n",
            "  [ 3.15939873e-01  8.67782533e-02 -3.23906422e-01 ...  6.30090460e-02\n",
            "   -3.14597517e-01 -1.88370496e-01]\n",
            "  [ 5.33324599e-01  1.40997484e-01 -3.74860108e-01 ... -3.68574224e-02\n",
            "   -3.53178293e-01 -2.16807783e-01]\n",
            "  ...\n",
            "  [-1.57103285e-01 -2.86872268e-01 -3.88842762e-01 ...  1.19546689e-01\n",
            "   -2.58011431e-01 -8.06739330e-02]\n",
            "  [-1.05153270e-01 -3.17780912e-01 -3.79753232e-01 ...  6.58106059e-02\n",
            "   -1.52741298e-01 -1.41171381e-01]\n",
            "  [-3.36468016e-04 -3.78462702e-01 -2.73814648e-01 ...  4.37965877e-02\n",
            "   -2.19456121e-01 -2.00145021e-01]]\n",
            "\n",
            " [[ 4.99618910e-02  1.59633040e-01 -3.59790176e-01 ...  1.48830101e-01\n",
            "   -3.90186012e-01 -1.25538632e-01]\n",
            "  [ 3.09935600e-01  1.27015248e-01 -3.64171028e-01 ...  4.89944257e-02\n",
            "   -3.39841872e-01 -1.94093421e-01]\n",
            "  [ 5.04508495e-01  1.93792924e-01 -3.92525226e-01 ... -1.72431059e-02\n",
            "   -3.22819620e-01 -1.82932019e-01]\n",
            "  ...\n",
            "  [-1.58330157e-01 -2.97645211e-01 -4.01978970e-01 ...  1.26249209e-01\n",
            "   -2.24605218e-01 -8.14321861e-02]\n",
            "  [-1.01416990e-01 -3.39203089e-01 -3.74351472e-01 ...  7.30864704e-02\n",
            "   -1.69893399e-01 -1.47182465e-01]\n",
            "  [-2.94527691e-02 -3.81232291e-01 -2.44166672e-01 ...  8.38359352e-03\n",
            "   -2.16930091e-01 -1.87269196e-01]]\n",
            "\n",
            " [[ 7.24458620e-02  1.57641172e-01 -3.32144916e-01 ...  1.23938784e-01\n",
            "   -3.94924879e-01 -1.44549295e-01]\n",
            "  [ 2.59683579e-01  1.26952261e-01 -3.39935005e-01 ...  6.14556372e-02\n",
            "   -3.71470958e-01 -1.73237756e-01]\n",
            "  [ 4.56056595e-01  2.10675180e-01 -3.87281299e-01 ... -1.43621424e-02\n",
            "   -3.39887083e-01 -1.75109595e-01]\n",
            "  ...\n",
            "  [-1.42348021e-01 -2.90059924e-01 -3.72800469e-01 ...  1.12950243e-01\n",
            "   -2.32498348e-01 -7.13138953e-02]\n",
            "  [-1.35053217e-01 -3.36502880e-01 -3.72147590e-01 ...  8.85727182e-02\n",
            "   -1.49306878e-01 -1.50618881e-01]\n",
            "  [ 1.84921995e-02 -3.58647466e-01 -2.69802392e-01 ...  2.04105545e-02\n",
            "   -2.23842904e-01 -1.67815864e-01]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 1.09100893e-01  1.54052988e-01 -3.55133235e-01 ...  1.54314920e-01\n",
            "   -3.38826120e-01 -1.60839826e-01]\n",
            "  [ 2.99482733e-01  1.17298856e-01 -3.54087442e-01 ...  5.34023531e-02\n",
            "   -3.51626903e-01 -1.80245623e-01]\n",
            "  [ 5.16088963e-01  1.59873798e-01 -3.78257990e-01 ... -2.90683601e-02\n",
            "   -3.26725811e-01 -2.07190126e-01]\n",
            "  ...\n",
            "  [-1.27946347e-01 -2.68279821e-01 -3.96274745e-01 ...  1.17471680e-01\n",
            "   -2.24364653e-01 -6.42711893e-02]\n",
            "  [-1.34190246e-01 -3.56493831e-01 -3.67209256e-01 ...  7.12345839e-02\n",
            "   -1.67674467e-01 -1.28541946e-01]\n",
            "  [-3.22168972e-03 -3.69747818e-01 -2.53290087e-01 ...  2.53550597e-02\n",
            "   -2.20210224e-01 -1.95157588e-01]]\n",
            "\n",
            " [[ 7.85631165e-02  1.78574204e-01 -3.63878846e-01 ...  1.44988373e-01\n",
            "   -3.57410252e-01 -1.68696925e-01]\n",
            "  [ 3.30073565e-01  1.11059904e-01 -3.29477668e-01 ...  1.97064281e-02\n",
            "   -3.15279722e-01 -1.99409112e-01]\n",
            "  [ 5.12250185e-01  1.84763923e-01 -3.46406817e-01 ... -4.59306873e-02\n",
            "   -3.68375361e-01 -2.14790151e-01]\n",
            "  ...\n",
            "  [-1.31243303e-01 -2.95480996e-01 -3.99288148e-01 ...  1.23571448e-01\n",
            "   -2.17617750e-01 -7.54154027e-02]\n",
            "  [-9.72082987e-02 -3.49082112e-01 -3.52831274e-01 ...  6.40288070e-02\n",
            "   -1.45341128e-01 -1.34124056e-01]\n",
            "  [-7.02240155e-04 -3.88524801e-01 -2.40957886e-01 ...  3.62569615e-02\n",
            "   -2.20212042e-01 -1.88845620e-01]]\n",
            "\n",
            " [[ 8.92543420e-02  1.70689061e-01 -3.53009999e-01 ...  1.44405201e-01\n",
            "   -3.68923783e-01 -1.52524799e-01]\n",
            "  [ 3.09926480e-01  1.09455407e-01 -3.27742696e-01 ...  3.04785371e-02\n",
            "   -3.76737535e-01 -1.76279828e-01]\n",
            "  [ 5.08465350e-01  1.97931215e-01 -3.15917969e-01 ... -3.20777446e-02\n",
            "   -2.91552156e-01 -2.24499792e-01]\n",
            "  ...\n",
            "  [-1.66680396e-01 -2.75622070e-01 -3.79693657e-01 ...  1.30985066e-01\n",
            "   -2.44316638e-01 -5.70558570e-02]\n",
            "  [-1.25673756e-01 -3.60696346e-01 -3.69772375e-01 ...  7.38945529e-02\n",
            "   -1.42748967e-01 -1.58735022e-01]\n",
            "  [-1.07871993e-02 -3.90690267e-01 -2.64307946e-01 ...  8.46173335e-03\n",
            "   -1.89084679e-01 -1.83049172e-01]]]\n",
            "(16, 32) (16, 32, 65)\n"
          ]
        }
      ],
      "source": [
        "test_decoder_model(decoder_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVkbeg0YgKYHGUl1KA4vOB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}